{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 1.导入包以及设置随机种子\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd59e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.以类的方式定义超参数\n",
    "class argparse():\n",
    "    pass\n",
    "\n",
    "args = argparse()\n",
    "\n",
    "# 固定参数\n",
    "\n",
    "args.patience = 30      #early stopping相关\n",
    "args.dimension = 4\n",
    "\n",
    "# 可优化参数\n",
    "args.epochs =300\n",
    "args.BTACH_SIZE =512     \n",
    "args.data = pd.read_csv('./rainfall_traindata.csv')\n",
    "args.delay =72\n",
    "args.device= [torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),]\n",
    "args.layers=2\n",
    "\n",
    "args.data.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e43a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据集函数  \n",
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "def build_databbase(sequence_length,delay,data):\n",
    "    data_ = []\n",
    "    for i in range(len(data) - sequence_length - delay):\n",
    "        data_.append(data.iloc[i: i + sequence_length + delay])\n",
    "\n",
    "    data_ = np.array([df.values for df in data_])\n",
    "    np.random.shuffle(data_)\n",
    "    x = data_[:, :-delay, :]\n",
    "    y = data_[:, -1, 0]\n",
    "    #y = data_[:,-delay:, 0]\n",
    "\n",
    "    x = x.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "   \n",
    "    #根据6：2：2的比例划分训练集和测试集\n",
    "    split_boundary = int(data_.shape[0] * 0.8)\n",
    "\n",
    "    train_x = x[: split_boundary]\n",
    "    test_x = x[split_boundary:]\n",
    "\n",
    "    train_y = y[: split_boundary]\n",
    "    test_y = y[split_boundary:]\n",
    "\n",
    "    mean = train_x.mean(axis=0)\n",
    "    std = train_x.std(axis=0)\n",
    "    train_x = (train_x - mean)/std\n",
    "    test_x = (test_x - mean)/std\n",
    "    train_ds = Mydataset(train_x, train_y)\n",
    "    test_ds = Mydataset(test_x, test_y)\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "                                           train_ds,\n",
    "                                           batch_size=args.BTACH_SIZE,\n",
    "                                           shuffle=True\n",
    "    )\n",
    "    test_dl = torch.utils.data.DataLoader(\n",
    "                                           test_ds,\n",
    "                                           batch_size=args.BTACH_SIZE\n",
    "    )\n",
    "    return train_dl,test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.LSTM(args.dimension, \n",
    "                           hidden_size,\n",
    "                           args.layers,\n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "       \n",
    "        s_o,_ = self.rnn(inputs)\n",
    "        s_o = s_o[:, -1, :]\n",
    "        x = F.dropout(F.relu(self.fc1(s_o)),0.2,training=True)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.定义early stopping\n",
    "class EarlyStopping():\n",
    "    def __init__(self,patience=7,verbose=False,delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        \n",
    "    def __call__(self,val_loss,model,path):\n",
    "        #print(\"val_loss={}\".format(val_loss))\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss,model,path)\n",
    "        elif score < self.best_score+self.delta:\n",
    "            self.counter+=1\n",
    "            #print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter>=self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss,model,path)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self,val_loss,model,path):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), path+'/'+'model_earlystopping.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22689b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.定义训练函数\n",
    "def fit(epoch, model, trainloader, testloader,optimizer):\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "#    exp_lr_scheduler.step()\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        \n",
    "        \n",
    "    test_total = 0\n",
    "    test_running_loss = 0 \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.to('cuda'), y.to('cuda')\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "    \n",
    "        \n",
    "    #print('epoch: ', epoch, \n",
    "    #      'loss： ', round(epoch_loss, 3),\n",
    "    #      'test_loss： ', round(epoch_test_loss, 3),\n",
    "    #         )\n",
    "    \n",
    "        \n",
    "    return epoch_loss, epoch_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.PSO寻优算法\n",
    "#\n",
    "# 10.1 define PSO\n",
    "class PSO(object):\n",
    "    def __init__(self,particle_num,particle_dim,iter_num,c1,c2,w,max_value,min_value):\n",
    "        '''参数初始化\n",
    "        particle_num(int):粒子群的粒子数量\n",
    "        particle_dim(int):粒子维度，对应待寻优参数的个数\n",
    "        iter_num(int):最大迭代次数\n",
    "        c1(float):局部学习因子，表示粒子移动到该粒子历史最优位置(pbest)的加速项的权重\n",
    "        c2(float):全局学习因子，表示粒子移动到所有粒子最优位置(gbest)的加速项的权重\n",
    "        w(float):惯性因子，表示粒子之前运动方向在本次方向上的惯性\n",
    "        max_value(float):参数的最大值\n",
    "        min_value(float):参数的最小值\n",
    "        '''\n",
    "        self.particle_num = particle_num ##\n",
    "        self.particle_dim = particle_dim ##本例中使用2个，分别对应[hidden_size, learning_rate]\n",
    "        self.iter_num = iter_num\n",
    "        self.c1 = c1  ##通常设为2.0\n",
    "        self.c2 = c2  ##通常设为2.0\n",
    "        self.w = w    \n",
    "        self.max_value = max_value ##200\n",
    "        self.min_value = min_value ##0\n",
    "        \n",
    "        \n",
    "# 10.2 initial particle swarm\n",
    "    def swarm_origin(self):\n",
    "        '''粒子群初始化\n",
    "        input:self(object):PSO类\n",
    "        output:particle_loc(list):粒子群位置列表\n",
    "               particle_dir(list):粒子群方向列表\n",
    "        '''\n",
    "        particle_loc = []\n",
    "        particle_dir = []\n",
    "        for i in range(self.particle_num):\n",
    "            tmp1 = []\n",
    "            tmp2 = []\n",
    "            for j in range(self.particle_dim):\n",
    "                a = random.random()\n",
    "                b = random.random()\n",
    "                tmp1.append(a * (self.max_value[j] - self.min_value[j]) + self.min_value[j])\n",
    "                tmp2.append(b)\n",
    "            particle_loc.append(tmp1)\n",
    "            particle_dir.append(tmp2)\n",
    "        \n",
    "        return particle_loc,particle_dir\n",
    "\n",
    "# 10.3 计算适应度函数数值列表;初始化pbest_parameters和gbest_parameter   \n",
    "    def fitness(self,particle_loc):\n",
    "        '''计算适应度函数值\n",
    "        input:self(object):PSO类\n",
    "              particle_loc(list):粒子群位置列表\n",
    "        output:fitness_value(list):适应度函数值列表\n",
    "        '''\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        train_epochs_loss = []\n",
    "        valid_epochs_loss = []\n",
    "        fitness_value = []\n",
    "        ### 1.适应度函数为loss值\n",
    "        for i in range(self.particle_num):\n",
    "            print(f\"{i}/{self.particle_num} particle.\")\n",
    "            #构建数据集\n",
    "            train_dl,test_dl=build_databbase(int(particle_loc[i][2]),args.delay,args.data)#时间步长\n",
    "            criterion = torch.nn.MSELoss()\n",
    "            lst = Net(int(particle_loc[i][0])+2)#hidden_size值\n",
    "            opti = torch.optim.Adam(lst.parameters(), lr=particle_loc[i][1])\n",
    "            criterion = torch.nn.MSELoss()\n",
    "            early_stopping = EarlyStopping(patience=args.patience)\n",
    "            print(particle_loc[i][0],particle_loc[i][1],particle_loc[i][2])\n",
    "            for epoch in range(args.epochs):\n",
    "                lst.to('cuda')\n",
    "                epoch_loss, epoch_test_loss = fit(epoch,\n",
    "                                                  lst,\n",
    "                                                  train_dl,\n",
    "                                                  test_dl,\n",
    "                                                  opti)\n",
    "    \n",
    "                train_loss.append(epoch_loss)\n",
    "                test_loss.append(epoch_test_loss)\n",
    "                #==================early stopping======================\n",
    "                early_stopping(test_loss[-1],model=lst,path='./models')\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            # rbf_svm = svm.SVC(kernel = 'rbf', C = particle_loc[i][0], gamma = particle_loc[i][1])\n",
    "            # cv_scores = cross_validation.cross_val_score(rbf_svm,trainX,trainY,cv =3,scoring = 'accuracy')\n",
    "            print(\"val_loss={}\".format(test_loss[-1]))\n",
    "            fitness_value.append(-test_loss[-1])\n",
    "        ### 2. 当前粒子群最优适应度函数值和对应的参数\n",
    "        current_fitness = -1000.0\n",
    "        current_parameter = []\n",
    "        for i in range(self.particle_num):\n",
    "            if current_fitness < fitness_value[i]:\n",
    "                current_fitness = fitness_value[i]\n",
    "                current_parameter = particle_loc[i]\n",
    "\n",
    "        return fitness_value,current_fitness,current_parameter \n",
    "        \n",
    "\n",
    "## 10.4  粒子位置更新 \n",
    "    def updata(self,particle_loc,particle_dir,gbest_parameter,pbest_parameters):\n",
    "        '''粒子群位置更新\n",
    "        input:self(object):PSO类\n",
    "              particle_loc(list):粒子群位置列表\n",
    "              particle_dir(list):粒子群方向列表\n",
    "              gbest_parameter(list):全局最优参数\n",
    "              pbest_parameters(list):每个粒子的历史最优值\n",
    "        output:particle_loc(list):新的粒子群位置列表\n",
    "               particle_dir(list):新的粒子群方向列表\n",
    "        '''\n",
    "        ## 1.计算新的量子群方向和粒子群位置\n",
    "        for i in range(self.particle_num): \n",
    "            a1 = [x * self.w for x in particle_dir[i]]\n",
    "            a2 = [y * self.c1 * random.random() for y in list(np.array(pbest_parameters[i]) - np.array(particle_loc[i]))]\n",
    "            a3 = [z * self.c2 * random.random() for z in list(np.array(gbest_parameter) - np.array(particle_dir[i]))]\n",
    "            particle_dir[i] = list(np.array(a1) + np.array(a2) + np.array(a3))\n",
    "            # particle_dir[i] = self.w * particle_dir[i] + self.c1 * random.random() * (pbest_parameters[i] - particle_loc[i]) + self.c2 * random.random() * (gbest_parameter - particle_dir[i])\n",
    "            particle_loc[i] = list(np.array(particle_loc[i]) + np.array(particle_dir[i]))\n",
    "            \n",
    "        ## 2.将更新后的量子位置参数固定在[min_value,max_value]内 \n",
    "        ### 2.1 每个参数的取值列表\n",
    "        parameter_list = []\n",
    "        for i in range(self.particle_dim):\n",
    "            tmp1 = []\n",
    "            for j in range(self.particle_num):\n",
    "                tmp1.append(particle_loc[j][i])\n",
    "            parameter_list.append(tmp1)\n",
    "        ### 2.2 每个参数取值的最大值、最小值、平均值   \n",
    "        value = []\n",
    "        for i in range(self.particle_dim):\n",
    "            tmp2 = []\n",
    "            tmp2.append(max(parameter_list[i]))\n",
    "            tmp2.append(min(parameter_list[i]))\n",
    "            value.append(tmp2)\n",
    "        \n",
    "        for i in range(self.particle_num):\n",
    "            for j in range(self.particle_dim):\n",
    "                particle_loc[i][j] = (particle_loc[i][j] - value[j][1])/(value[j][0] - value[j][1]) * (self.max_value[j] - self.min_value[j]) + self.min_value[j]\n",
    "                \n",
    "        return particle_loc,particle_dir\n",
    "\n",
    "## 10.5 画出适应度函数值变化图\n",
    "    def plot(self,results):\n",
    "        '''画图\n",
    "        '''\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(self.iter_num):\n",
    "            X.append(i + 1)\n",
    "            Y.append(results[i])\n",
    "        plt.plot(X,Y)\n",
    "        plt.xlabel('Number of iteration',size = 15)\n",
    "        plt.ylabel('Value of CV',size = 15)\n",
    "        plt.title('PSO_RBF_SVM parameter optimization')\n",
    "        plt.savefig(\"rainpso.png\",dpi=800,bbox_inches = 'tight')\n",
    "        plt.show() \n",
    "        \n",
    "## 10.6 主函数        \n",
    "    def main(self):\n",
    "        '''主函数\n",
    "        '''\n",
    "        results = []\n",
    "        best_fitness = -1000.0 \n",
    "        ## 1、粒子群初始化\n",
    "        particle_loc,particle_dir = self.swarm_origin()\n",
    "        ## 2、初始化gbest_parameter、pbest_parameters、fitness_value列表\n",
    "        ### 2.1 gbest_parameter\n",
    "        gbest_parameter = []\n",
    "        for i in range(self.particle_dim):\n",
    "            gbest_parameter.append(-1000)\n",
    "        ### 2.2 pbest_parameters\n",
    "        pbest_parameters = []\n",
    "        for i in range(self.particle_num):\n",
    "            tmp1 = []\n",
    "            for j in range(self.particle_dim):\n",
    "                tmp1.append(-1000)\n",
    "            pbest_parameters.append(tmp1)\n",
    "        ### 2.3 fitness_value\n",
    "        fitness_value = []\n",
    "        for i in range(self.particle_num):\n",
    "            fitness_value.append(-1000)\n",
    "    \n",
    "        ## 3.迭代\n",
    "        for i in range(self.iter_num):\n",
    "            print(f\"{i}/{self.iter_num} iter of current particle.\")\n",
    "            ### 3.1 计算当前适应度函数值列表\n",
    "            current_fitness_value,current_best_fitness,current_best_parameter = self.fitness(particle_loc)\n",
    "            ### 3.2 求当前的gbest_parameter、pbest_parameters和best_fitness\n",
    "            for j in range(self.particle_num):\n",
    "                if current_fitness_value[j] > fitness_value[j]:\n",
    "                    pbest_parameters[j] = particle_loc[j]\n",
    "            if current_best_fitness > best_fitness:\n",
    "                best_fitness = current_best_fitness\n",
    "                gbest_parameter = current_best_parameter\n",
    "            \n",
    "            print('iteration is :',i+1,';Best parameters:',gbest_parameter,';Best fitness(loss)',best_fitness)\n",
    "            results.append(best_fitness)\n",
    "            ### 3.3 更新fitness_value\n",
    "            fitness_value = current_fitness_value\n",
    "            ### 3.4 更新粒子群\n",
    "            particle_loc,particle_dir = self.updata(particle_loc,particle_dir,gbest_parameter,pbest_parameters)\n",
    "        ## 4.结果展示\n",
    "        results.sort()\n",
    "        self.plot(results)\n",
    "        print('Final parameters are :',gbest_parameter)\n",
    "        return gbest_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175041c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(particle_num=20,particle_dim=3,iter_num=50,c1=2,c2=2,w=0.8,max_value=[80,0.01,300],min_value=[5,0.0001,96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbest_parameter=pso.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b303395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用最佳参数训练模型\n",
    "\n",
    "train_dl,test_dl,test_y=build_databbase(gbest_parameter[2],args.delay,args.data)\n",
    "\n",
    "model = Net(gbest_parameter[0])\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=gbest_parameter[1])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=args.patience)\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    epoch_loss, epoch_test_loss = fit(epoch,\n",
    "                                      model,\n",
    "                                      train_dl,\n",
    "                                      test_dl)\n",
    "\n",
    "    train_loss.append(epoch_loss)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    #==================early stopping======================\n",
    "    early_stopping(test_loss[-1],model=model,path='./models')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"耗时: {:.2f}秒\".format(end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "torch.save(model, \"./models/PSO_lstm_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.10-cpu",
   "language": "python",
   "name": "torch1.10-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
